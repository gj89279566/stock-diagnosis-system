#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‚¡ç¥¨ç»¼åˆè¯„ä»·ç³»ç»Ÿ
æ•´åˆå¤šä¸ªæƒå¨æ•°æ®æºï¼Œç”Ÿæˆç»¼åˆæŠ•èµ„å»ºè®®
"""

import requests
from bs4 import BeautifulSoup
import json
import re
from datetime import datetime
import pandas as pd
import numpy as np
from snownlp import SnowNLP

class StockAnalyzer:
    """è‚¡ç¥¨åˆ†æå™¨"""
    
    def __init__(self, stock_code, stock_name):
        self.stock_code = stock_code
        self.stock_name = stock_name
        self.headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"}
        
    def fetch_all_news(self):
        """è·å–æ‰€æœ‰å¯ç”¨æ•°æ®æºçš„æ–°é—»"""
        print(f"ğŸ“° æ­£åœ¨è·å– {self.stock_name} çš„æ–°é—»æ•°æ®...")
        
        all_news = []
        source_results = {}
        
        # 1. æ–°æµªè´¢ç»æ–°é—»ï¼ˆä¸»è¦æ•°æ®æºï¼‰
        sina_news = self.fetch_sina_news()
        if sina_news:
            all_news.extend(sina_news)
            source_results['æ–°æµªè´¢ç»'] = len(sina_news)
            print(f"âœ… æ–°æµªè´¢ç»: {len(sina_news)} æ¡æ–°é—»")
        
        # 2. ä¸œæ–¹è´¢å¯Œæ–°é—»ï¼ˆå¤‡ç”¨æ•°æ®æºï¼‰
        eastmoney_news = self.fetch_eastmoney_news()
        if eastmoney_news:
            all_news.extend(eastmoney_news)
            source_results['ä¸œæ–¹è´¢å¯Œ'] = len(eastmoney_news)
            print(f"âœ… ä¸œæ–¹è´¢å¯Œ: {len(eastmoney_news)} æ¡å…¬å‘Š")
        
        # å»é‡
        unique_news = []
        seen_titles = set()
        for date, title in all_news:
            if title not in seen_titles:
                unique_news.append((date, title))
                seen_titles.add(title)
        
        print(f"ğŸ“Š æ€»è®¡è·å– {len(unique_news)} æ¡æ–°é—»ï¼ˆå»é‡åï¼‰")
        print(f"ğŸ“ˆ æ•°æ®æºè´¡çŒ®: {source_results}")
        
        return unique_news, source_results
    
    def fetch_sina_news(self):
        """è·å–æ–°æµªè´¢ç»æ–°é—»"""
        url = "https://vip.stock.finance.sina.com.cn/corp/view/vCB_AllNewsStock.php"
        params = {"symbol": self.stock_code, "Page": 1}
        
        try:
            resp = requests.get(url, params=params, headers=self.headers, timeout=10)
            if resp.status_code == 200:
                resp.encoding = 'gbk'
                soup = BeautifulSoup(resp.text, 'html.parser')
                
                news_container = soup.find('div', class_='datelist')
                if news_container:
                    news_pattern = r'(\d{4}-\d{2}-\d{2})\s+(\d{2}:\d{2})\s+<a[^>]*>([^<]+)</a>'
                    news_matches = re.findall(news_pattern, str(news_container))
                    
                    news_list = []
                    for match in news_matches:
                        date_str = match[0]
                        time_str = match[1]
                        title = match[2].strip()
                        full_date = f"{date_str} {time_str}"
                        news_list.append((full_date, title))
                    
                    return news_list
        except Exception as e:
            print(f"âŒ æ–°æµªè´¢ç»è·å–å¤±è´¥: {e}")
        
        return []
    
    def fetch_eastmoney_news(self):
        """è·å–ä¸œæ–¹è´¢å¯Œæ–°é—»"""
        url = "http://np-anotice-stock.eastmoney.com/api/security/announcement/getAnnouncementList"
        params = {"cb": "jQuery", "pageSize": 20, "pageIndex": 1, "stock": self.stock_code}
        
        try:
            resp = requests.get(url, params=params, headers=self.headers, timeout=10)
            if resp.status_code == 200 and resp.text:
                content = resp.text
                news_list = []
                
                # å°è¯•è§£æJSONPæ ¼å¼
                if content.startswith('jQuery(') and content.endswith(')'):
                    json_str = content[7:-1]
                    try:
                        data = json.loads(json_str)
                        if 'data' in data and 'list' in data['data']:
                            news_items = data['data']['list']
                            for item in news_items:
                                date_str = item.get('notice_date', '')
                                title = item.get('title', '')
                                if date_str and title:
                                    news_list.append((date_str, title))
                            return news_list
                    except json.JSONDecodeError:
                        pass
        except Exception as e:
            print(f"âŒ ä¸œæ–¹è´¢å¯Œè·å–å¤±è´¥: {e}")
        
        return []
    
    def analyze_sentiment(self, news_list):
        """åˆ†ææ–°é—»æƒ…ç»ª"""
        print(f"\nğŸ“Š æ­£åœ¨åˆ†ææ–°é—»æƒ…ç»ª...")
        
        if not news_list:
            return "ä¸­æ€§", 0, 0, 0, 0.5
        
        count_positive = 0
        count_negative = 0
        count_neutral = 0
        sentiment_scores = []
        
        print("ğŸ“° è¯¦ç»†æƒ…ç»ªåˆ†æ:")
        for i, (date, title) in enumerate(news_list[:10]):  # æ˜¾ç¤ºå‰10æ¡
            s = SnowNLP(title)
            score = s.sentiments
            sentiment_scores.append(score)
            
            if score > 0.7:
                count_positive += 1
                sentiment = "æ­£é¢"
            elif score < 0.3:
                count_negative += 1
                sentiment = "è´Ÿé¢"
            else:
                count_neutral += 1
                sentiment = "ä¸­æ€§"
            
            if i < 10:
                print(f"  {date}: {title[:50]}... (æƒ…ç»ª: {sentiment}, åˆ†æ•°: {score:.2f})")
        
        # è®¡ç®—æ€»ä½“æƒ…ç»ª
        total = len(news_list)
        avg_score = sum(sentiment_scores) / len(sentiment_scores) if sentiment_scores else 0.5
        
        sentiment_label = "ä¸­æ€§"
        if total > 0:
            if count_negative > count_positive * 1.5:
                sentiment_label = "è´Ÿé¢"
            elif count_positive > count_negative * 1.5:
                sentiment_label = "æ­£é¢"
        
        print(f"\nğŸ“ˆ æ–°é—»æƒ…ç»ªç»Ÿè®¡: æ­£é¢{count_positive}æ¡, ä¸­æ€§{count_neutral}æ¡, è´Ÿé¢{count_negative}æ¡")
        print(f"ğŸ“Š å¹³å‡æƒ…ç»ªåˆ†æ•°: {avg_score:.2f}")
        print(f"ğŸ¯ æ€»ä½“æ–°é—»æƒ…ç»ªå€¾å‘: {sentiment_label}")
        
        return sentiment_label, count_positive, count_neutral, count_negative, avg_score
    
    def fetch_stock_data(self):
        """è·å–è‚¡ç¥¨æŠ€æœ¯æ•°æ®"""
        print(f"\nğŸ“ˆ æ­£åœ¨è·å– {self.stock_name} çš„æŠ€æœ¯æ•°æ®...")
        
        # ä½¿ç”¨æ–°æµªæ•°æ®æºè·å–è‚¡ç¥¨æ•°æ®
        url = "http://money.finance.sina.com.cn/quotes_service/api/json_v2.php/CN_MarketData.getKLineData"
        params = {"symbol": self.stock_code, "scale": 240, "ma": 5, "datalen": 100}
        
        try:
            resp = requests.get(url, params=params, headers=self.headers, timeout=10)
            if resp.status_code == 200:
                data = resp.json()
                if data:
                    df_data = []
                    for item in data:
                        df_data.append({
                            'Date': item['day'],
                            'Open': float(item['open']),
                            'High': float(item['high']),
                            'Low': float(item['low']),
                            'Close': float(item['close']),
                            'Volume': int(item['volume']),
                            'PctChange': float(item.get('pct_chg', 0))
                        })
                    
                    df = pd.DataFrame(df_data)
                    df['Date'] = pd.to_datetime(df['Date'])
                    df.sort_values('Date', inplace=True)
                    df.reset_index(drop=True, inplace=True)
                    
                    # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
                    df['MA5'] = df['Close'].rolling(window=5).mean()
                    df['MA10'] = df['Close'].rolling(window=10).mean()
                    df['MA20'] = df['Close'].rolling(window=20).mean()
                    df['EMA12'] = df['Close'].ewm(span=12, adjust=False).mean()
                    df['EMA26'] = df['Close'].ewm(span=26, adjust=False).mean()
                    df['Diff'] = df['EMA12'] - df['EMA26']
                    df['DEA'] = df['Diff'].ewm(span=9, adjust=False).mean()
                    df['MACD_hist'] = 2 * (df['Diff'] - df['DEA'])
                    
                    # KDJè®¡ç®—
                    low_list = df['Low'].rolling(window=9).min()
                    high_list = df['High'].rolling(window=9).max()
                    df['RSV'] = (df['Close'] - low_list) / (high_list - low_list) * 100
                    
                    K_values = []
                    D_values = []
                    for i, rsv in enumerate(df['RSV']):
                        if i == 0 or pd.isna(rsv):
                            K = 50.0
                            D = 50.0
                        else:
                            if pd.isna(rsv):
                                rsv = K_values[-1]
                            K = K_values[-1] * 2/3 + rsv * 1/3
                            D = D_values[-1] * 2/3 + K * 1/3
                        K_values.append(K)
                        D_values.append(D)
                    
                    df['K'] = K_values
                    df['D'] = D_values
                    df['J'] = 3 * df['K'] - 2 * df['D']
                    
                    # è·å–æœ€æ–°æ•°æ®
                    latest = df.iloc[-1]
                    recent_vol_avg = df['Volume'].iloc[-6:-1].mean() if len(df) > 5 else df['Volume'].mean()
                    
                    tech_data = {
                        'last_date': latest['Date'].strftime("%Y-%m-%d"),
                        'last_close': latest['Close'],
                        'pct_change': latest['PctChange'],
                        'volume': latest['Volume'],
                        'ma5': latest['MA5'],
                        'ma10': latest['MA10'],
                        'ma20': latest['MA20'],
                        'diff': latest['Diff'],
                        'dea': latest['DEA'],
                        'macd_hist': latest['MACD_hist'],
                        'K': latest['K'],
                        'D': latest['D'],
                        'J': latest['J'],
                        'volume_high': latest['Volume'] > 1.2 * recent_vol_avg,
                        'oversold': latest['K'] < 20 and latest['D'] < 20,
                        'overbought': latest['K'] > 80 and latest['D'] > 80
                    }
                    
                    print(f"âœ… æŠ€æœ¯æ•°æ®è·å–æˆåŠŸ")
                    return df, tech_data
                    
        except Exception as e:
            print(f"âŒ æŠ€æœ¯æ•°æ®è·å–å¤±è´¥: {e}")
        
        return None, None
    
    def calculate_comprehensive_score(self, sentiment_label, tech_data, avg_sentiment_score):
        """è®¡ç®—ç»¼åˆè¯„åˆ†"""
        print(f"\nğŸ¯ æ­£åœ¨è®¡ç®—ç»¼åˆè¯„åˆ†...")
        
        # 1. æ–°é—»æƒ…ç»ªè¯„åˆ† (0-100åˆ†)
        sentiment_score = 0
        if sentiment_label == "æ­£é¢":
            sentiment_score = 80 + (avg_sentiment_score - 0.5) * 40  # 80-100åˆ†
        elif sentiment_label == "è´Ÿé¢":
            sentiment_score = 20 + (avg_sentiment_score - 0.5) * 40  # 0-40åˆ†
        else:  # ä¸­æ€§
            sentiment_score = 40 + (avg_sentiment_score - 0.5) * 40  # 40-60åˆ†
        
        # 2. æŠ€æœ¯æŒ‡æ ‡è¯„åˆ† (0-100åˆ†)
        tech_score = 50  # åŸºç¡€åˆ†
        
        # MACDè¯„åˆ†
        if tech_data.get('diff', 0) > tech_data.get('dea', 0):
            tech_score += 10  # å¤šå¤´è¶‹åŠ¿
        else:
            tech_score -= 10  # ç©ºå¤´è¶‹åŠ¿
        
        # KDJè¯„åˆ†
        k_value = tech_data.get('K', 50)
        d_value = tech_data.get('D', 50)
        if k_value < 20 and d_value < 20:
            tech_score += 15  # è¶…å–ï¼Œä¹°å…¥ä¿¡å·
        elif k_value > 80 and d_value > 80:
            tech_score -= 15  # è¶…ä¹°ï¼Œå–å‡ºä¿¡å·
        
        # å‡çº¿è¯„åˆ†
        ma5 = tech_data.get('ma5', 0)
        ma10 = tech_data.get('ma10', 0)
        ma20 = tech_data.get('ma20', 0)
        close = tech_data.get('last_close', 0)
        
        if close > ma5 > ma10 > ma20:
            tech_score += 10  # å¤šå¤´æ’åˆ—
        elif close < ma5 < ma10 < ma20:
            tech_score -= 10  # ç©ºå¤´æ’åˆ—
        
        # æˆäº¤é‡è¯„åˆ†
        if tech_data.get('volume_high', False):
            tech_score += 5  # æˆäº¤é‡æ”¾å¤§
        
        # æ¶¨è·Œå¹…è¯„åˆ†
        pct_change = tech_data.get('pct_change', 0)
        if pct_change > 3:
            tech_score += 5  # å¤§æ¶¨
        elif pct_change < -3:
            tech_score -= 5  # å¤§è·Œ
        
        # ç¡®ä¿åˆ†æ•°åœ¨0-100èŒƒå›´å†…
        tech_score = max(0, min(100, tech_score))
        
        # 3. ç»¼åˆè¯„åˆ† (æ–°é—»40% + æŠ€æœ¯60%)
        final_score = sentiment_score * 0.4 + tech_score * 0.6
        
        print(f"ğŸ“Š è¯„åˆ†è¯¦æƒ…:")
        print(f"  æ–°é—»æƒ…ç»ªè¯„åˆ†: {sentiment_score:.1f}/100")
        print(f"  æŠ€æœ¯æŒ‡æ ‡è¯„åˆ†: {tech_score:.1f}/100")
        print(f"  ç»¼åˆè¯„åˆ†: {final_score:.1f}/100")
        
        return final_score, sentiment_score, tech_score
    
    def generate_investment_advice(self, final_score):
        """ç”ŸæˆæŠ•èµ„å»ºè®®"""
        if final_score >= 80:
            signal = "å¼ºçƒˆä¹°å…¥"
            confidence = "é«˜"
            risk_level = "ä½"
        elif final_score >= 65:
            signal = "ä¹°å…¥"
            confidence = "ä¸­é«˜"
            risk_level = "ä½"
        elif final_score >= 45:
            signal = "æŒæœ‰"
            confidence = "ä¸­"
            risk_level = "ä¸­"
        elif final_score >= 30:
            signal = "è§‚æœ›"
            confidence = "ä¸­ä½"
            risk_level = "ä¸­"
        else:
            signal = "å–å‡º"
            confidence = "é«˜"
            risk_level = "é«˜"
        
        return signal, confidence, risk_level
    
    def generate_report(self, news_list, sentiment_data, tech_data, scores, advice):
        """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š"""
        print(f"\nğŸ“„ æ­£åœ¨ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š...")
        
        filename = f"{self.stock_name}_ç»¼åˆè¯„ä»·æŠ¥å‘Š.txt"
        
        with open(filename, "w", encoding="utf-8") as f:
            f.write(f"{self.stock_name}è‚¡ç¥¨ç»¼åˆè¯„ä»·æŠ¥å‘Š\n")
            f.write("="*60 + "\n")
            f.write(f"åˆ†ææ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"è‚¡ç¥¨ä»£ç ï¼š{self.stock_code}\n\n")
            
            # æ–°é—»åˆ†æ
            f.write("ğŸ“° æ–°é—»æƒ…ç»ªåˆ†æ\n")
            f.write("-"*40 + "\n")
            f.write(f"æ–°é—»æ€»æ•°ï¼š{len(news_list)} æ¡\n")
            f.write(f"æ­£é¢æ–°é—»ï¼š{sentiment_data[1]} æ¡\n")
            f.write(f"ä¸­æ€§æ–°é—»ï¼š{sentiment_data[2]} æ¡\n")
            f.write(f"è´Ÿé¢æ–°é—»ï¼š{sentiment_data[3]} æ¡\n")
            f.write(f"å¹³å‡æƒ…ç»ªåˆ†æ•°ï¼š{sentiment_data[4]:.2f}\n")
            f.write(f"æ€»ä½“æƒ…ç»ªå€¾å‘ï¼š{sentiment_data[0]}\n")
            f.write(f"æƒ…ç»ªè¯„åˆ†ï¼š{scores[1]:.1f}/100\n\n")
            
            # æŠ€æœ¯åˆ†æ
            f.write("ğŸ“ˆ æŠ€æœ¯æŒ‡æ ‡åˆ†æ\n")
            f.write("-"*40 + "\n")
            f.write(f"æœ€æ–°äº¤æ˜“æ—¥ï¼š{tech_data['last_date']}\n")
            f.write(f"æ”¶ç›˜ä»·ï¼š{tech_data['last_close']:.2f} å…ƒ\n")
            f.write(f"æ¶¨è·Œå¹…ï¼š{tech_data['pct_change']:.2f}%\n")
            f.write(f"æˆäº¤é‡ï¼š{tech_data['volume']:,}\n")
            f.write(f"å‡çº¿ç³»ç»Ÿï¼šMA5={tech_data['ma5']:.2f}, MA10={tech_data['ma10']:.2f}, MA20={tech_data['ma20']:.2f}\n")
            f.write(f"MACDæŒ‡æ ‡ï¼šDIF={tech_data['diff']:.2f}, DEA={tech_data['dea']:.2f}\n")
            f.write(f"KDJæŒ‡æ ‡ï¼šK={tech_data['K']:.1f}, D={tech_data['D']:.1f}, J={tech_data['J']:.1f}\n")
            f.write(f"æŠ€æœ¯ä¿¡å·ï¼š{'è¶…å–' if tech_data['oversold'] else ('è¶…ä¹°' if tech_data['overbought'] else 'æ­£å¸¸')}\n")
            f.write(f"æŠ€æœ¯è¯„åˆ†ï¼š{scores[2]:.1f}/100\n\n")
            
            # ç»¼åˆè¯„åˆ†
            f.write("ğŸ¯ ç»¼åˆè¯„åˆ†\n")
            f.write("-"*40 + "\n")
            f.write(f"æ–°é—»æƒ…ç»ªæƒé‡ï¼š40%\n")
            f.write(f"æŠ€æœ¯æŒ‡æ ‡æƒé‡ï¼š60%\n")
            f.write(f"ç»¼åˆè¯„åˆ†ï¼š{scores[0]:.1f}/100\n\n")
            
            # æŠ•èµ„å»ºè®®
            f.write("ğŸ’¡ æŠ•èµ„å»ºè®®\n")
            f.write("-"*40 + "\n")
            f.write(f"æ“ä½œå»ºè®®ï¼š{advice[0]}\n")
            f.write(f"ç½®ä¿¡åº¦ï¼š{advice[1]}\n")
            f.write(f"é£é™©ç­‰çº§ï¼š{advice[2]}\n\n")
            
            # é£é™©æç¤º
            f.write("âš ï¸ é£é™©æç¤º\n")
            f.write("-"*40 + "\n")
            f.write("1. æœ¬åˆ†æåŸºäºå…¬å¼€æ•°æ®ï¼Œä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®\n")
            f.write("2. è‚¡å¸‚æœ‰é£é™©ï¼ŒæŠ•èµ„éœ€è°¨æ…\n")
            f.write("3. è¯·ç»“åˆè‡ªèº«é£é™©æ‰¿å—èƒ½åŠ›åšå‡ºæŠ•èµ„å†³ç­–\n")
            f.write("4. å»ºè®®åˆ†æ•£æŠ•èµ„ï¼Œä¸è¦å°†æ‰€æœ‰èµ„é‡‘æŠ•å…¥å•ä¸€è‚¡ç¥¨\n")
            f.write("5. å®šæœŸå…³æ³¨å…¬å¸å…¬å‘Šå’Œè¡Œä¸šåŠ¨æ€\n\n")
            
            # æœ€æ–°æ–°é—»åˆ—è¡¨
            f.write("ğŸ“° æœ€æ–°ç›¸å…³æ–°é—»\n")
            f.write("-"*40 + "\n")
            for i, (date, title) in enumerate(news_list[:20]):
                f.write(f"{i+1}. {date}: {title}\n")
        
        print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜è‡³: {filename}")
        return filename
    
    def run_analysis(self):
        """è¿è¡Œå®Œæ•´åˆ†æ"""
        print(f"ğŸš€ å¼€å§‹åˆ†æ {self.stock_name} ({self.stock_code})")
        print("="*60)
        
        # 1. è·å–æ–°é—»æ•°æ®
        news_list, source_results = self.fetch_all_news()
        
        # 2. åˆ†ææ–°é—»æƒ…ç»ª
        sentiment_data = self.analyze_sentiment(news_list)
        
        # 3. è·å–æŠ€æœ¯æ•°æ®
        df, tech_data = self.fetch_stock_data()
        if tech_data is None:
            print("âŒ æ— æ³•è·å–æŠ€æœ¯æ•°æ®ï¼Œåˆ†æç»ˆæ­¢")
            return
        
        # 4. è®¡ç®—ç»¼åˆè¯„åˆ†
        scores = self.calculate_comprehensive_score(sentiment_data[0], tech_data, sentiment_data[4])
        
        # 5. ç”ŸæˆæŠ•èµ„å»ºè®®
        advice = self.generate_investment_advice(scores[0])
        
        # 6. æ˜¾ç¤ºç»“æœ
        print(f"\n========= ç»¼åˆåˆ†æç»“è®º =========")
        print(f"ğŸ“° æ–°é—»é¢æƒ…ç»ª: {sentiment_data[0]}")
        print(f"ğŸ“ˆ æŠ€æœ¯é¢ä¿¡å·: {'è¶…å–' if tech_data['oversold'] else ('è¶…ä¹°' if tech_data['overbought'] else 'æ­£å¸¸')}")
        print(f"ğŸ¯ ç»¼åˆè¯„åˆ†: {scores[0]:.1f}/100")
        print(f"ğŸ’¡ æ“ä½œå»ºè®®: {advice[0]} (ç½®ä¿¡åº¦: {advice[1]}, é£é™©: {advice[2]})")
        
        # 7. ç”ŸæˆæŠ¥å‘Š
        report_file = self.generate_report(news_list, sentiment_data, tech_data, scores, advice)
        
        print(f"\nâœ… {self.stock_name} åˆ†æå®Œæˆï¼")
        print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_file}")
        
        return {
            'news_count': len(news_list),
            'sentiment': sentiment_data[0],
            'tech_score': scores[2],
            'final_score': scores[0],
            'advice': advice[0],
            'confidence': advice[1],
            'risk_level': advice[2]
        }

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ è‚¡ç¥¨ç»¼åˆè¯„ä»·ç³»ç»Ÿ")
    print("="*60)
    
    # åˆ†æè¯æ˜åº·å¾·
    analyzer = StockAnalyzer("sh603259", "è¯æ˜åº·å¾·")
    result = analyzer.run_analysis()
    
    print(f"\nğŸ‰ åˆ†æå®Œæˆï¼")
    print(f"ğŸ“Š ç»“æœæ‘˜è¦:")
    print(f"  æ–°é—»æ•°é‡: {result['news_count']} æ¡")
    print(f"  æƒ…ç»ªå€¾å‘: {result['sentiment']}")
    print(f"  æŠ€æœ¯è¯„åˆ†: {result['tech_score']:.1f}/100")
    print(f"  ç»¼åˆè¯„åˆ†: {result['final_score']:.1f}/100")
    print(f"  æŠ•èµ„å»ºè®®: {result['advice']}")
    print(f"  ç½®ä¿¡åº¦: {result['confidence']}")
    print(f"  é£é™©ç­‰çº§: {result['risk_level']}")

if __name__ == "__main__":
    main() 