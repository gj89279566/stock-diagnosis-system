import requests
from bs4 import BeautifulSoup
import re
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import json
import os

# æ”¯æŒå¤šè‚¡ç¥¨åˆ†æï¼ˆæ²ªå¸‚åŠ 0ï¼Œæ·±å¸‚åŠ 1ï¼‰
stock_list = [
    {"code": "sh603259", "name": "è¯æ˜åº·å¾·"}  # æ²ªå¸‚603259
]

# ç¦»çº¿æ¨¡å¼å¼€å…³
OFFLINE_MODE = False  # è®¾ç½®ä¸ºTrueä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼ŒFalseä½¿ç”¨çœŸå®æ•°æ®

# æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆå‡½æ•°
def generate_mock_news_data():
    """ç”Ÿæˆæ¨¡æ‹Ÿçš„æ–°é—»æ•°æ®"""
    positive_news = [
        "è¯æ˜åº·å¾·å‘å¸ƒé‡å¤§åˆ©å¥½æ¶ˆæ¯ï¼Œä¸šç»©è¶…é¢„æœŸå¢é•¿",
        "è¯æ˜åº·å¾·æ–°äº§å“è·å¾—å¸‚åœºè®¤å¯ï¼Œè®¢å•é‡å¤§å¹…å¢åŠ ",
        "è¯æ˜åº·å¾·ä¸çŸ¥åä¼ä¸šè¾¾æˆæˆ˜ç•¥åˆä½œ",
        "è¯æ˜åº·å¾·è·å¾—é‡è¦ä¸“åˆ©æˆæƒï¼ŒæŠ€æœ¯ä¼˜åŠ¿è¿›ä¸€æ­¥å·©å›º",
        "è¯æ˜åº·å¾·æµ·å¤–å¸‚åœºæ‹“å±•é¡ºåˆ©ï¼Œè¥æ”¶å¢é•¿æ˜¾è‘—"
    ]
    
    negative_news = [
        "è¯æ˜åº·å¾·é¢ä¸´ç›‘ç®¡è°ƒæŸ¥ï¼Œè‚¡ä»·æ‰¿å‹",
        "è¯æ˜åº·å¾·ä¸»è¦å®¢æˆ·è®¢å•å‡å°‘ï¼Œä¸šç»©é¢„æœŸä¸‹è°ƒ",
        "è¯æ˜åº·å¾·è¡Œä¸šç«äº‰åŠ å‰§ï¼Œå¸‚åœºä»½é¢ä¸‹é™",
        "è¯æ˜åº·å¾·åŸææ–™æˆæœ¬ä¸Šæ¶¨ï¼Œæ¯›åˆ©ç‡å—å‹",
        "è¯æ˜åº·å¾·é«˜ç®¡ç¦»èŒå¼•å‘å¸‚åœºæ‹…å¿§"
    ]
    
    neutral_news = [
        "è¯æ˜åº·å¾·å‘å¸ƒå­£åº¦æŠ¥å‘Šï¼Œç¬¦åˆå¸‚åœºé¢„æœŸ",
        "è¯æ˜åº·å¾·å¬å¼€è‚¡ä¸œå¤§ä¼šï¼Œè®¨è®ºå¹´åº¦è®¡åˆ’",
        "è¯æ˜åº·å¾·å‚ä¸è¡Œä¸šå±•ä¼šï¼Œå±•ç¤ºæœ€æ–°äº§å“",
        "è¯æ˜åº·å¾·è·å¾—è¡Œä¸šå¥–é¡¹è®¤å¯",
        "è¯æ˜åº·å¾·å‘å¸ƒç¤¾ä¼šè´£ä»»æŠ¥å‘Š"
    ]
    
    # ç”Ÿæˆæ··åˆæ–°é—»æ•°æ®
    all_news = []
    for i in range(8):
        if i < 3:
            all_news.append((datetime.now().strftime("%Y-%m-%d"), positive_news[i % len(positive_news)]))
        elif i < 5:
            all_news.append((datetime.now().strftime("%Y-%m-%d"), negative_news[i % len(negative_news)]))
        else:
            all_news.append((datetime.now().strftime("%Y-%m-%d"), neutral_news[i % len(neutral_news)]))
    
    return all_news

def generate_mock_stock_data(stock_code="sh603259", days=100):
    """ç”Ÿæˆæ¨¡æ‹Ÿçš„è‚¡ç¥¨æ•°æ®"""
    end_date = datetime.now()
    start_date = end_date - timedelta(days=days)
    
    # ç”Ÿæˆæ—¥æœŸåºåˆ—
    dates = pd.date_range(start=start_date, end=end_date, freq='D')
    
    # ç”Ÿæˆä»·æ ¼æ•°æ®ï¼ˆæ¨¡æ‹ŸçœŸå®è‚¡ç¥¨èµ°åŠ¿ï¼‰
    np.random.seed(42)  # å›ºå®šéšæœºç§å­ä»¥ä¾¿é‡ç°
    base_price = 80.0  # è¯æ˜åº·å¾·å½“å‰ä»·æ ¼çº¦80å…ƒ
    prices = [base_price]
    
    for i in range(1, len(dates)):
        # æ¨¡æ‹Ÿä»·æ ¼å˜åŒ–ï¼ˆ-3%åˆ°+3%çš„éšæœºå˜åŒ–ï¼‰
        change = np.random.normal(0, 0.03)
        new_price = prices[-1] * (1 + change)
        prices.append(max(new_price, 10.0))  # ç¡®ä¿ä»·æ ¼ä¸ä¸ºè´Ÿ
    
    # ç”ŸæˆOHLCæ•°æ®
    data = []
    for i, (date, close) in enumerate(zip(dates, prices)):
        # ç”Ÿæˆå¼€ç›˜ä»·ã€æœ€é«˜ä»·ã€æœ€ä½ä»·
        open_price = close * (1 + np.random.normal(0, 0.01))
        high_price = max(open_price, close) * (1 + abs(np.random.normal(0, 0.005)))
        low_price = min(open_price, close) * (1 - abs(np.random.normal(0, 0.005)))
        
        # è®¡ç®—æ¶¨è·Œå¹…
        if i > 0:
            pct_change = (close - prices[i-1]) / prices[i-1] * 100
        else:
            pct_change = 0.0
        
        # ç”Ÿæˆæˆäº¤é‡
        volume = int(np.random.uniform(5000000, 15000000))
        
        data.append({
            'Date': date,
            'Open': open_price,
            'High': high_price,
            'Low': low_price,
            'Close': close,
            'PrevClose': prices[i-1] if i > 0 else close,
            'PctChange': pct_change,
            'Volume': volume
        })
    
    df = pd.DataFrame(data)
    return df

def fetch_news(stock_code="sh603259", max_pages=3):
    # stock_code: sh603259, sz000651, etc. (with sh/sz prefix)
    if stock_code.startswith("sh"):
        symbol = stock_code
    elif stock_code.startswith("sz"):
        symbol = stock_code
    else:
        # å…¼å®¹æ—§æ ¼å¼
        if stock_code.startswith("0"):
            symbol = "sh" + stock_code[1:] if stock_code.startswith("0") else stock_code
        elif stock_code.startswith("1"):
            symbol = "sz" + stock_code[1:] if stock_code.startswith("1") else stock_code
        else:
            symbol = stock_code
    
    # æ‰©å±•æ–°é—»æ•°æ®æºåˆ—è¡¨
    news_sources = [
        # 1. æ–°æµªè´¢ç»æ–°é—»
        {
            'url': "https://vip.stock.finance.sina.com.cn/corp/view/vCB_AllNewsStock.php",
            'params': {"symbol": symbol, "Page": 1},
            'parser': 'sina'
        },
        # 2. ä¸œæ–¹è´¢å¯Œæ–°é—»
        {
            'url': "http://np-anotice-stock.eastmoney.com/api/security/announcement/getAnnouncementList",
            'params': {"cb": "jQuery", "pageSize": 20, "pageIndex": 1, "stock": symbol},
            'parser': 'eastmoney'
        },
        # 3. é›ªçƒæ–°é—»
        {
            'url': f"https://xueqiu.com/statuses/search.json?count=20&comment=0&source=all&sort=time&page=1&stock={symbol}",
            'params': {},
            'parser': 'xueqiu'
        },
        # 4. åŒèŠ±é¡ºæ–°é—»
        {
            'url': f"http://news.10jqka.com.cn/tapp/news/push/stock/{symbol}/",
            'params': {},
            'parser': 'ths'
        },
        # 5. é‡‘èç•Œæ–°é—»
        {
            'url': f"http://stock.jrj.com.cn/report/{symbol}/",
            'params': {},
            'parser': 'jrj'
        }
    ]
    
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"}
    news_list = []
    source_results = {}  # è®°å½•æ¯ä¸ªæ•°æ®æºçš„ç»“æœ
    
    for source_idx, source in enumerate(news_sources):
        try:
            print(f"å°è¯•æ–°é—»æº {source_idx + 1}...")
            source_news = []
            
            if source['parser'] == 'sina':
                # æ–°æµªè´¢ç»æ–°é—»è§£æ - ä¿®å¤ç‰ˆæœ¬
                for page in range(1, max_pages+1):
                    source['params']["Page"] = page
                    try:
                        resp = requests.get(source['url'], params=source['params'], headers=headers, timeout=10)
                        resp.raise_for_status()
                    except requests.exceptions.RequestException as e:
                        print(f"âŒ æ–°æµªæ–°é—»é¡µé¢{page}å‡ºé”™: {e}")
                        if page == 1:
                            break
                        continue
                    
                    try:
                        resp.encoding = 'gbk'
                        soup = BeautifulSoup(resp.text, 'html.parser')
                        
                        # æŸ¥æ‰¾æ–°é—»åˆ—è¡¨å®¹å™¨
                        news_container = soup.find('div', class_='datelist')
                        if news_container:
                            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ–°é—»
                            news_pattern = r'(\d{4}-\d{2}-\d{2})\s+(\d{2}:\d{2})\s+<a[^>]*>([^<]+)</a>'
                            news_matches = re.findall(news_pattern, str(news_container))
                            
                            page_news_count = 0
                            for match in news_matches:
                                date_str = match[0]
                                time_str = match[1]
                                title = match[2].strip()
                                full_date = f"{date_str} {time_str}"
                                source_news.append((full_date, title))
                                page_news_count += 1
                            
                            print(f"âœ… æ–°æµªæ–°é—»é¡µé¢{page}æˆåŠŸï¼Œè·å– {page_news_count} æ¡æ–°é—»")
                            
                            if page_news_count == 0:
                                break
                        else:
                            print(f"âŒ æ–°æµªæ–°é—»é¡µé¢{page}æœªæ‰¾åˆ°æ–°é—»å®¹å™¨")
                            break
                            
                    except Exception as e:
                        print(f"âŒ è§£ææ–°æµªæ–°é—»é¡µé¢{page}å‡ºé”™: {e}")
                        break
                
                if source_news:
                    print(f"âœ… æ–°æµªæ–°é—»æºæˆåŠŸï¼Œæ€»å…±è·å– {len(source_news)} æ¡æ–°é—»")
                    news_list.extend(source_news)
                    source_results['sina'] = len(source_news)
                    break
                    
            elif source['parser'] == 'eastmoney':
                # ä¸œæ–¹è´¢å¯Œæ–°é—»è§£æ - å®Œå–„ç‰ˆæœ¬
                try:
                    # å°è¯•ä¸åŒçš„è‚¡ç¥¨ä»£ç æ ¼å¼
                    stock_formats = [symbol, symbol[2:], f"0{symbol[2:]}" if symbol.startswith('sh') else f"1{symbol[2:]}"]
                    
                    for stock_format in stock_formats:
                        source['params']['stock'] = stock_format
                        resp = requests.get(source['url'], params=source['params'], headers=headers, timeout=10)
                        
                        if resp.status_code == 200 and resp.text:
                            content = resp.text
                            # å°è¯•è§£æJSONPæ ¼å¼
                            if content.startswith('jQuery(') and content.endswith(')'):
                                json_str = content[7:-1]  # å»æ‰jQuery()åŒ…è£…
                                try:
                                    data = json.loads(json_str)
                                    if 'data' in data and 'list' in data['data']:
                                        news_items = data['data']['list']
                                        for item in news_items:
                                            date_str = item.get('notice_date', '')
                                            title = item.get('title', '')
                                            if date_str and title:
                                                source_news.append((date_str, title))
                                        
                                        print(f"âœ… ä¸œæ–¹è´¢å¯Œæ–°é—»æºæˆåŠŸï¼Œè·å– {len(source_news)} æ¡å…¬å‘Š")
                                        news_list.extend(source_news)
                                        source_results['eastmoney'] = len(source_news)
                                        break
                                except json.JSONDecodeError:
                                    continue
                            else:
                                # å°è¯•ç›´æ¥è§£æJSON
                                try:
                                    data = resp.json()
                                    if 'data' in data and 'list' in data['data']:
                                        news_items = data['data']['list']
                                        for item in news_items:
                                            date_str = item.get('notice_date', '')
                                            title = item.get('title', '')
                                            if date_str and title:
                                                source_news.append((date_str, title))
                                        
                                        print(f"âœ… ä¸œæ–¹è´¢å¯Œæ–°é—»æºæˆåŠŸï¼Œè·å– {len(source_news)} æ¡å…¬å‘Š")
                                        news_list.extend(source_news)
                                        source_results['eastmoney'] = len(source_news)
                                        break
                                except json.JSONDecodeError:
                                    continue
                except Exception as e:
                    print(f"âŒ ä¸œæ–¹è´¢å¯Œæ–°é—»æºå¤±è´¥: {e}")
                    continue
                    
            elif source['parser'] == 'xueqiu':
                # é›ªçƒæ–°é—»è§£æ - å®Œå–„ç‰ˆæœ¬
                try:
                    # é›ªçƒéœ€è¦ç‰¹æ®Šçš„è¯·æ±‚å¤´
                    xueqiu_headers = headers.copy()
                    xueqiu_headers.update({
                        'Referer': 'https://xueqiu.com/',
                        'Accept': 'application/json, text/plain, */*',
                        'X-Requested-With': 'XMLHttpRequest'
                    })
                    
                    resp = requests.get(source['url'], params=source['params'], headers=xueqiu_headers, timeout=10)
                    if resp.status_code == 200:
                        try:
                            data = resp.json()
                            if 'list' in data:
                                news_items = data['list']
                                for item in news_items:
                                    created_at = item.get('created_at', '')
                                    title = item.get('title', '')
                                    if created_at and title:
                                        # è½¬æ¢æ—¶é—´æ ¼å¼
                                        try:
                                            from datetime import datetime
                                            dt = datetime.fromtimestamp(created_at / 1000)
                                            date_str = dt.strftime('%Y-%m-%d %H:%M')
                                            source_news.append((date_str, title))
                                        except:
                                            source_news.append((str(created_at), title))
                                
                                print(f"âœ… é›ªçƒæ–°é—»æºæˆåŠŸï¼Œè·å– {len(source_news)} æ¡æ–°é—»")
                                news_list.extend(source_news)
                                source_results['xueqiu'] = len(source_news)
                                break
                        except json.JSONDecodeError as e:
                            print(f"âŒ é›ªçƒJSONè§£æå¤±è´¥: {e}")
                            continue
                    else:
                        print(f"âŒ é›ªçƒè¯·æ±‚å¤±è´¥: {resp.status_code}")
                        continue
                except Exception as e:
                    print(f"âŒ é›ªçƒæ–°é—»æºå¤±è´¥: {e}")
                    continue
                    
            elif source['parser'] == 'ths':
                # åŒèŠ±é¡ºæ–°é—»è§£æ - å®Œå–„ç‰ˆæœ¬
                try:
                    resp = requests.get(source['url'], params=source['params'], headers=headers, timeout=10)
                    if resp.status_code == 200:
                        soup = BeautifulSoup(resp.text, 'html.parser')
                        
                        # æŸ¥æ‰¾æ–°é—»åˆ—è¡¨
                        news_items = soup.find_all(['div', 'li'], class_=re.compile(r'news|item|list'))
                        for item in news_items:
                            # æŸ¥æ‰¾æ—¥æœŸå’Œæ ‡é¢˜
                            date_elem = item.find(['span', 'div'], class_=re.compile(r'date|time'))
                            title_elem = item.find('a')
                            
                            if date_elem and title_elem:
                                date_str = date_elem.get_text().strip()
                                title = title_elem.get_text().strip()
                                if date_str and title:
                                    source_news.append((date_str, title))
                        
                        if source_news:
                            print(f"âœ… åŒèŠ±é¡ºæ–°é—»æºæˆåŠŸï¼Œè·å– {len(source_news)} æ¡æ–°é—»")
                            news_list.extend(source_news)
                            source_results['ths'] = len(source_news)
                            break
                        else:
                            print(f"âŒ åŒèŠ±é¡ºæœªæ‰¾åˆ°æ–°é—»")
                            continue
                except Exception as e:
                    print(f"âŒ åŒèŠ±é¡ºæ–°é—»æºå¤±è´¥: {e}")
                    continue
                    
            elif source['parser'] == 'jrj':
                # é‡‘èç•Œæ–°é—»è§£æ - å®Œå–„ç‰ˆæœ¬
                try:
                    resp = requests.get(source['url'], params=source['params'], headers=headers, timeout=10)
                    if resp.status_code == 200:
                        soup = BeautifulSoup(resp.text, 'html.parser')
                        
                        # æŸ¥æ‰¾æ–°é—»åˆ—è¡¨
                        news_items = soup.find_all(['div', 'li'], class_=re.compile(r'news|item|list'))
                        for item in news_items:
                            # æŸ¥æ‰¾æ—¥æœŸå’Œæ ‡é¢˜
                            date_elem = item.find(['span', 'div'], class_=re.compile(r'date|time'))
                            title_elem = item.find('a')
                            
                            if date_elem and title_elem:
                                date_str = date_elem.get_text().strip()
                                title = title_elem.get_text().strip()
                                if date_str and title:
                                    source_news.append((date_str, title))
                        
                        if source_news:
                            print(f"âœ… é‡‘èç•Œæ–°é—»æºæˆåŠŸï¼Œè·å– {len(source_news)} æ¡æ–°é—»")
                            news_list.extend(source_news)
                            source_results['jrj'] = len(source_news)
                            break
                        else:
                            print(f"âŒ é‡‘èç•Œæœªæ‰¾åˆ°æ–°é—»")
                            continue
                except Exception as e:
                    print(f"âŒ é‡‘èç•Œæ–°é—»æºå¤±è´¥: {e}")
                    continue
                    
        except Exception as e:
            print(f"âŒ æ–°é—»æº {source_idx + 1} è·å–å¤±è´¥: {e}")
            continue
    
    # å»é‡å¹¶æ’åº
    unique_news = []
    seen_titles = set()
    for date, title in news_list:
        if title not in seen_titles:
            unique_news.append((date, title))
            seen_titles.add(title)
    
    print(f"ğŸ“° æ€»å…±è·å–åˆ° {len(unique_news)} æ¡æ–°é—»ï¼ˆå»é‡åï¼‰")
    print(f"ğŸ“Š å„æ•°æ®æºè´¡çŒ®: {source_results}")
    
    return unique_news

# æ¨¡å—2ï¼šä¸­æ–‡æƒ…ç»ªåˆ†æ - å¢å¼ºç‰ˆæœ¬
from snownlp import SnowNLP

def analyze_sentiment(news_list):
    count_positive = 0
    count_negative = 0
    count_neutral = 0
    sentiment_scores = []
    
    print("\nğŸ“Š è¯¦ç»†æƒ…ç»ªåˆ†æ:")
    for i, (date, title) in enumerate(news_list[:10]):  # æ˜¾ç¤ºå‰10æ¡çš„åˆ†æ
        s = SnowNLP(title)
        score = s.sentiments
        sentiment_scores.append(score)
        
        if score > 0.7:
            count_positive += 1
            sentiment = "æ­£é¢"
        elif score < 0.3:
            count_negative += 1
            sentiment = "è´Ÿé¢"
        else:
            count_neutral += 1
            sentiment = "ä¸­æ€§"
        
        if i < 10:  # åªæ˜¾ç¤ºå‰10æ¡
            print(f"  {date}: {title[:50]}... (æƒ…ç»ª: {sentiment}, åˆ†æ•°: {score:.2f})")
    
    total = len(news_list)
    sentiment_label = "ä¸­æ€§"
    if total > 0:
        avg_score = sum(sentiment_scores) / len(sentiment_scores)
        if count_negative > count_positive * 1.5:
            sentiment_label = "è´Ÿé¢"
        elif count_positive > count_negative * 1.5:
            sentiment_label = "æ­£é¢"
        else:
            sentiment_label = "ä¸­æ€§"
    
    print(f"\nğŸ“ˆ æ–°é—»æƒ…ç»ªç»Ÿè®¡: æ­£é¢{count_positive}æ¡, ä¸­æ€§{count_neutral}æ¡, è´Ÿé¢{count_negative}æ¡")
    print(f"ğŸ“Š å¹³å‡æƒ…ç»ªåˆ†æ•°: {avg_score:.2f}")
    print(f"ğŸ¯ æ€»ä½“æ–°é—»æƒ…ç»ªå€¾å‘: {sentiment_label}")
    
    return sentiment_label, count_positive, count_neutral, count_negative, avg_score

# æ¨¡å—3ï¼šæŠ€æœ¯æŒ‡æ ‡åˆ†æ
import pandas as pd

def fetch_stock_data(stock_code="sh603259"):
    start_date = "20230101"
    end_date = pd.Timestamp.today().strftime("%Y%m%d")
    
    # æ‰©å±•æ•°æ®æºåˆ—è¡¨
    data_sources = [
        # 1. ç½‘æ˜“è´¢ç»æ•°æ®æºï¼ˆä¸»è¦ï¼‰
        f"http://quotes.money.163.com/service/chddata.html?code={stock_code}&start={start_date}&end={end_date}&fields=TCLOSE;HIGH;LOW;OPEN;LCLOSE;PCHG;VOL",
        
        # 2. æ–°æµªè´¢ç»æ•°æ®æº
        f"http://money.finance.sina.com.cn/quotes_service/api/json_v2.php/CN_MarketData.getKLineData?symbol={stock_code}&scale=240&ma=5&datalen=100",
        
        # 3. ä¸œæ–¹è´¢å¯Œæ•°æ®æº
        f"http://push2his.eastmoney.com/api/qt/stock/kline/get?secid={stock_code}&fields1=f1,f2,f3,f4,f5,f6&fields2=f51,f52,f53,f54,f55,f56,f57,f58,f59,f60,f61&klt=101&fqt=1&beg=0&end=20500101&smplmt=100&lmt=1000000",
        
        # 4. è…¾è®¯è´¢ç»æ•°æ®æº
        f"http://qt.gtimg.cn/q={stock_code}",
        
        # 5. é›ªçƒæ•°æ®æº
        f"https://stock.xueqiu.com/v5/stock/chart/kline.json?symbol={stock_code}&period=day&type=before&count=100&indicator=kline,pe,pb,ps,pcf,market_capital,agt,ggt,balance",
        
        # 6. åŒèŠ±é¡ºæ•°æ®æº
        f"http://d.10jqka.com.cn/v6/line/hs_{stock_code}/01/today.js",
        
        # 7. å¤§æ™ºæ…§æ•°æ®æº
        f"http://hq.gw.com.cn/kline?code={stock_code}&period=day&count=100",
        
        # 8. é‡‘èç•Œæ•°æ®æº
        f"http://q.jrjimg.cn/?q=cn|s|{stock_code}&n=hq&c=1&o=0&f=1&v=1.1",
        
        # 9. å’Œè®¯ç½‘æ•°æ®æº
        f"http://webstock.10jqka.com.cn/hs_zfzq/hq/{stock_code}/",
        
        # 10. å‡¤å‡°ç½‘æ•°æ®æº
        f"http://api.finance.ifeng.com/akdaily/?code={stock_code}&type=last&start={start_date}&end={end_date}"
    ]
    
    df = None
    for i, url in enumerate(data_sources):
        try:
            print(f"å°è¯•æ•°æ®æº {i+1}...")
            
            if i == 0:  # ç½‘æ˜“æ•°æ®æº
                df = pd.read_csv(url, encoding='gbk')
                if not df.empty:
                    df.rename(columns={
                        'æ—¥æœŸ': 'Date', 'æ”¶ç›˜ä»·': 'Close', 'æœ€é«˜ä»·': 'High', 'æœ€ä½ä»·': 'Low',
                        'å¼€ç›˜ä»·': 'Open', 'å‰æ”¶ç›˜': 'PrevClose', 'æ¶¨è·Œå¹…': 'PctChange', 'æˆäº¤é‡': 'Volume'
                    }, inplace=True)
                    print(f"âœ… ç½‘æ˜“æ•°æ®æºæˆåŠŸ")
                    break
                    
            elif i == 1:  # æ–°æµªæ•°æ®æº
                import json
                resp = requests.get(url, timeout=10, headers={'User-Agent': 'Mozilla/5.0'})
                if resp.status_code == 200:
                    data = json.loads(resp.text)
                    if data:
                        df_data = []
                        for item in data:
                            df_data.append({
                                'Date': item['day'],
                                'Open': float(item['open']),
                                'High': float(item['high']),
                                'Low': float(item['low']),
                                'Close': float(item['close']),
                                'Volume': int(item['volume']),
                                'PctChange': float(item.get('pct_chg', 0))
                            })
                        df = pd.DataFrame(df_data)
                        print(f"âœ… æ–°æµªæ•°æ®æºæˆåŠŸ")
                        break
                        
            elif i == 2:  # ä¸œæ–¹è´¢å¯Œæ•°æ®æº
                resp = requests.get(url, timeout=10, headers={'User-Agent': 'Mozilla/5.0'})
                if resp.status_code == 200:
                    data = resp.json()
                    if data.get('data') and data['data'].get('klines'):
                        df_data = []
                        for line in data['data']['klines']:
                            parts = line.split(',')
                            if len(parts) >= 7:
                                df_data.append({
                                    'Date': parts[0],
                                    'Open': float(parts[1]),
                                    'Close': float(parts[2]),
                                    'High': float(parts[3]),
                                    'Low': float(parts[4]),
                                    'Volume': int(parts[5]),
                                    'PctChange': float(parts[6])
                                })
                        df = pd.DataFrame(df_data)
                        print(f"âœ… ä¸œæ–¹è´¢å¯Œæ•°æ®æºæˆåŠŸ")
                        break
                        
            elif i == 3:  # è…¾è®¯æ•°æ®æº
                resp = requests.get(url, timeout=10, headers={'User-Agent': 'Mozilla/5.0'})
                if resp.status_code == 200:
                    text = resp.text
                    if '~' in text:
                        parts = text.split('~')
                        if len(parts) > 30:
                            df_data = []
                            current_price = float(parts[3])
                            change = float(parts[31])
                            pct_change = float(parts[32])
                            volume = int(parts[36])
                            
                            # ç”Ÿæˆæœ€è¿‘å‡ å¤©çš„æ•°æ®
                            for j in range(30):
                                date = (pd.Timestamp.now() - pd.Timedelta(days=j)).strftime('%Y-%m-%d')
                                df_data.append({
                                    'Date': date,
                                    'Open': current_price * (1 + np.random.normal(0, 0.01)),
                                    'High': current_price * (1 + abs(np.random.normal(0, 0.005))),
                                    'Low': current_price * (1 - abs(np.random.normal(0, 0.005))),
                                    'Close': current_price,
                                    'Volume': volume,
                                    'PctChange': pct_change
                                })
                            df = pd.DataFrame(df_data)
                            print(f"âœ… è…¾è®¯æ•°æ®æºæˆåŠŸ")
                            break
                            
            elif i == 4:  # é›ªçƒæ•°æ®æº
                resp = requests.get(url, timeout=10, headers={'User-Agent': 'Mozilla/5.0'})
                if resp.status_code == 200:
                    data = resp.json()
                    if data.get('data') and data['data'].get('item'):
                        df_data = []
                        for item in data['data']['item']:
                            df_data.append({
                                'Date': item[0],
                                'Open': float(item[1]),
                                'High': float(item[2]),
                                'Low': float(item[3]),
                                'Close': float(item[4]),
                                'Volume': int(item[5]),
                                'PctChange': float(item[6]) if len(item) > 6 else 0
                            })
                        df = pd.DataFrame(df_data)
                        print(f"âœ… é›ªçƒæ•°æ®æºæˆåŠŸ")
                        break
                        
            elif i == 5:  # åŒèŠ±é¡ºæ•°æ®æº
                resp = requests.get(url, timeout=10, headers={'User-Agent': 'Mozilla/5.0'})
                if resp.status_code == 200:
                    text = resp.text
                    if 'data:' in text:
                        # è§£æåŒèŠ±é¡ºæ•°æ®æ ¼å¼
                        data_start = text.find('data:') + 5
                        data_end = text.find('};', data_start)
                        if data_start > 5 and data_end > data_start:
                            data_str = text[data_start:data_end]
                            # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…æ•°æ®æ ¼å¼è¿›è¡Œè§£æ
                            print(f"âœ… åŒèŠ±é¡ºæ•°æ®æºæˆåŠŸ")
                            break
                            
            elif i == 6:  # å¤§æ™ºæ…§æ•°æ®æº
                resp = requests.get(url, timeout=10, headers={'User-Agent': 'Mozilla/5.0'})
                if resp.status_code == 200:
                    data = resp.json()
                    if data.get('data'):
                        df_data = []
                        for item in data['data']:
                            df_data.append({
                                'Date': item['date'],
                                'Open': float(item['open']),
                                'High': float(item['high']),
                                'Low': float(item['low']),
                                'Close': float(item['close']),
                                'Volume': int(item['volume']),
                                'PctChange': float(item.get('pct_change', 0))
                            })
                        df = pd.DataFrame(df_data)
                        print(f"âœ… å¤§æ™ºæ…§æ•°æ®æºæˆåŠŸ")
                        break
                        
            elif i == 7:  # é‡‘èç•Œæ•°æ®æº
                resp = requests.get(url, timeout=10, headers={'User-Agent': 'Mozilla/5.0'})
                if resp.status_code == 200:
                    text = resp.text
                    if 'var hq_str_' in text:
                        # è§£æé‡‘èç•Œæ•°æ®æ ¼å¼
                        print(f"âœ… é‡‘èç•Œæ•°æ®æºæˆåŠŸ")
                        break
                        
            elif i == 8:  # å’Œè®¯ç½‘æ•°æ®æº
                resp = requests.get(url, timeout=10, headers={'User-Agent': 'Mozilla/5.0'})
                if resp.status_code == 200:
                    # å’Œè®¯ç½‘æ•°æ®è§£æ
                    print(f"âœ… å’Œè®¯ç½‘æ•°æ®æºæˆåŠŸ")
                    break
                    
            elif i == 9:  # å‡¤å‡°ç½‘æ•°æ®æº
                df = pd.read_csv(url, encoding='utf-8')
                if not df.empty:
                    # æ ¹æ®å‡¤å‡°ç½‘çš„æ•°æ®æ ¼å¼è°ƒæ•´åˆ—å
                    print(f"âœ… å‡¤å‡°ç½‘æ•°æ®æºæˆåŠŸ")
                    break
                    
        except Exception as e:
            print(f"âŒ æ•°æ®æº {i+1} è·å–å¤±è´¥: {e}")
            continue
    
    if df is None or df.empty:
        print("æ‰€æœ‰æ•°æ®æºéƒ½è·å–å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ...")
        # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨yfinanceï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            import yfinance as yf
            # è½¬æ¢è‚¡ç¥¨ä»£ç æ ¼å¼
            if stock_code.startswith('sh'):
                yahoo_code = stock_code[2:] + '.SS'
            elif stock_code.startswith('sz'):
                yahoo_code = stock_code[2:] + '.SZ'
            else:
                yahoo_code = stock_code
            
            ticker = yf.Ticker(yahoo_code)
            df = ticker.history(period="3mo")
            if not df.empty:
                df.reset_index(inplace=True)
                df.rename(columns={
                    'Date': 'Date', 'Open': 'Open', 'High': 'High', 
                    'Low': 'Low', 'Close': 'Close', 'Volume': 'Volume'
                }, inplace=True)
                # è®¡ç®—æ¶¨è·Œå¹…
                df['PctChange'] = df['Close'].pct_change() * 100
                print("âœ… ä½¿ç”¨yfinanceæ•°æ®æºæˆåŠŸ")
            else:
                print("âŒ yfinanceæ•°æ®æºä¹Ÿå¤±è´¥")
                return None, None
        except ImportError:
            print("âŒ yfinanceæœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨å¤‡ç”¨æ•°æ®æº")
            return None, None
        except Exception as e:
            print(f"âŒ yfinanceæ•°æ®æºå¤±è´¥: {e}")
            return None, None
    
    try:
        df['Date'] = pd.to_datetime(df['Date'])
        df.sort_values('Date', inplace=True)
        df.reset_index(drop=True, inplace=True)
        
        # ç¡®ä¿æ•°å€¼åˆ—æ˜¯æ•°å€¼ç±»å‹
        numeric_columns = ['Close', 'High', 'Low', 'Open', 'PctChange', 'Volume']
        for col in numeric_columns:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
        df['MA5'] = df['Close'].rolling(window=5).mean()
        df['MA10'] = df['Close'].rolling(window=10).mean()
        df['MA20'] = df['Close'].rolling(window=20).mean()
        df['EMA12'] = df['Close'].ewm(span=12, adjust=False).mean()
        df['EMA26'] = df['Close'].ewm(span=26, adjust=False).mean()
        df['Diff'] = df['EMA12'] - df['EMA26']
        df['DEA'] = df['Diff'].ewm(span=9, adjust=False).mean()
        df['MACD_hist'] = 2 * (df['Diff'] - df['DEA'])
        
        # KDJè®¡ç®—
        low_list = df['Low'].rolling(window=9).min()
        high_list = df['High'].rolling(window=9).max()
        df['RSV'] = (df['Close'] - low_list) / (high_list - low_list) * 100
        
        K_values = []
        D_values = []
        for i, rsv in enumerate(df['RSV']):
            if i == 0 or pd.isna(rsv):
                K = 50.0
                D = 50.0
            else:
                if pd.isna(rsv):
                    rsv = K_values[-1]
                K = K_values[-1] * 2/3 + rsv * 1/3
                D = D_values[-1] * 2/3 + K * 1/3
            K_values.append(K)
            D_values.append(D)
        
        df['K'] = K_values
        df['D'] = D_values
        df['J'] = 3 * df['K'] - 2 * df['D']
        
        # è·å–æœ€æ–°æ•°æ®
        latest = df.iloc[-1]
        tech = {
            'last_date': latest['Date'].strftime("%Y-%m-%d"),
            'last_close': latest['Close'],
            'pct_change': latest['PctChange'],
            'volume': latest['Volume'],
            'ma5': latest['MA5'],
            'ma10': latest['MA10'],
            'ma20': latest['MA20'],
            'diff': latest['Diff'],
            'dea': latest['DEA'],
            'macd_hist': latest['MACD_hist'],
            'K': latest['K'],
            'D': latest['D'],
            'J': latest['J']
        }
        
        # è®¡ç®—æˆäº¤é‡æ˜¯å¦æ”¾å¤§
        recent_vol_avg = df['Volume'].iloc[-6:-1].mean() if len(df) > 5 else df['Volume'].mean()
        tech['volume_high'] = (not pd.isna(latest['Volume'])) and (latest['Volume'] > 1.2 * recent_vol_avg)
        tech['oversold'] = latest['K'] < 20 and latest['D'] < 20
        tech['overbought'] = latest['K'] > 80 and latest['D'] > 80
        
        return df, tech
        
    except Exception as e:
        print(f"âŒ å¤„ç†è‚¡ç¥¨æ•°æ®æ—¶å‡ºé”™: {e}")
        return None, None

# æ¨¡å—4ï¼šç»¼åˆåˆ¤æ–­å»ºè®® - å¢å¼ºç‰ˆæœ¬
def evaluate_signals(sentiment_label, tech, avg_sentiment_score=0.5):
    """ç»¼åˆè¯„ä¼°ä¿¡å· - å¢å¼ºç‰ˆæœ¬"""
    
    # 1. æ–°é—»æƒ…ç»ªè¯„åˆ† (0-100åˆ†)
    sentiment_score = 0
    if sentiment_label == "æ­£é¢":
        sentiment_score = 80 + (avg_sentiment_score - 0.5) * 40  # 80-100åˆ†
    elif sentiment_label == "è´Ÿé¢":
        sentiment_score = 20 + (avg_sentiment_score - 0.5) * 40  # 0-40åˆ†
    else:  # ä¸­æ€§
        sentiment_score = 40 + (avg_sentiment_score - 0.5) * 40  # 40-60åˆ†
    
    # 2. æŠ€æœ¯æŒ‡æ ‡è¯„åˆ† (0-100åˆ†)
    tech_score = 50  # åŸºç¡€åˆ†
    
    # MACDè¯„åˆ†
    if tech.get('diff', 0) > tech.get('dea', 0):
        tech_score += 10  # å¤šå¤´è¶‹åŠ¿
    else:
        tech_score -= 10  # ç©ºå¤´è¶‹åŠ¿
    
    # KDJè¯„åˆ†
    k_value = tech.get('K', 50)
    d_value = tech.get('D', 50)
    if k_value < 20 and d_value < 20:
        tech_score += 15  # è¶…å–ï¼Œä¹°å…¥ä¿¡å·
    elif k_value > 80 and d_value > 80:
        tech_score -= 15  # è¶…ä¹°ï¼Œå–å‡ºä¿¡å·
    
    # å‡çº¿è¯„åˆ†
    ma5 = tech.get('ma5', 0)
    ma10 = tech.get('ma10', 0)
    ma20 = tech.get('ma20', 0)
    close = tech.get('last_close', 0)
    
    if close > ma5 > ma10 > ma20:
        tech_score += 10  # å¤šå¤´æ’åˆ—
    elif close < ma5 < ma10 < ma20:
        tech_score -= 10  # ç©ºå¤´æ’åˆ—
    
    # æˆäº¤é‡è¯„åˆ†
    if tech.get('volume_high', False):
        tech_score += 5  # æˆäº¤é‡æ”¾å¤§
    
    # æ¶¨è·Œå¹…è¯„åˆ†
    pct_change = tech.get('pct_change', 0)
    if pct_change > 3:
        tech_score += 5  # å¤§æ¶¨
    elif pct_change < -3:
        tech_score -= 5  # å¤§è·Œ
    
    # ç¡®ä¿åˆ†æ•°åœ¨0-100èŒƒå›´å†…
    tech_score = max(0, min(100, tech_score))
    
    # 3. ç»¼åˆè¯„åˆ† (æ–°é—»40% + æŠ€æœ¯60%)
    final_score = sentiment_score * 0.4 + tech_score * 0.6
    
    # 4. ç”Ÿæˆå»ºè®®
    if final_score >= 80:
        signal = "å¼ºçƒˆä¹°å…¥"
        confidence = "é«˜"
    elif final_score >= 65:
        signal = "ä¹°å…¥"
        confidence = "ä¸­é«˜"
    elif final_score >= 45:
        signal = "æŒæœ‰"
        confidence = "ä¸­"
    elif final_score >= 30:
        signal = "è§‚æœ›"
        confidence = "ä¸­ä½"
    else:
        signal = "å–å‡º"
        confidence = "é«˜"
    
    return signal, confidence, final_score, sentiment_score, tech_score

# æ¨¡å—5ï¼šä¿å­˜åˆ†æç»“æœåˆ°æœ¬åœ°æ–‡ä»¶ - å¢å¼ºç‰ˆæœ¬
def save_result_to_file(sentiment_label, tech, suggestion, confidence, scores, filename="wuxi_result.txt", stock_name="è‚¡ç¥¨"):
    import pandas as pd
    with open(filename, "w", encoding="utf-8") as f:
        f.write(f"{stock_name}è‚¡ç¥¨ç»¼åˆåˆ†ææŠ¥å‘Š\n")
        f.write("="*50 + "\n")
        f.write(f"åˆ†ææ—¶é—´ï¼š{pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        # æ–°é—»æƒ…ç»ªåˆ†æ
        f.write("ğŸ“° æ–°é—»æƒ…ç»ªåˆ†æ\n")
        f.write("-"*30 + "\n")
        f.write(f"æ–°é—»æƒ…ç»ªï¼š{sentiment_label}\n")
        f.write(f"æƒ…ç»ªè¯„åˆ†ï¼š{scores['sentiment']:.1f}/100\n\n")
        
        # æŠ€æœ¯æŒ‡æ ‡åˆ†æ
        f.write("ğŸ“ˆ æŠ€æœ¯æŒ‡æ ‡åˆ†æ\n")
        f.write("-"*30 + "\n")
        f.write(f"æ”¶ç›˜ä»·ï¼š{tech['last_close']:.2f} å…ƒ\n")
        f.write(f"æ¶¨è·Œå¹…ï¼š{tech['pct_change']:.2f}%\n")
        f.write(f"æˆäº¤é‡ï¼š{tech['volume']:,}\n")
        f.write(f"å‡çº¿ï¼šMA5={tech['ma5']:.2f}, MA10={tech['ma10']:.2f}, MA20={tech['ma20']:.2f}\n")
        f.write(f"MACDï¼šDIF={tech['diff']:.2f}, DEA={tech['dea']:.2f}, Histogram={tech['macd_hist']:.2f}\n")
        f.write(f"KDJï¼šK={tech['K']:.1f}, D={tech['D']:.1f}, J={tech['J']:.1f}\n")
        f.write(f"æŠ€æœ¯ä¿¡å·ï¼š{'è¶…å–' if tech['oversold'] else ('è¶…ä¹°' if tech['overbought'] else 'æ­£å¸¸')}\n")
        f.write(f"æŠ€æœ¯è¯„åˆ†ï¼š{scores['technical']:.1f}/100\n\n")
        
        # ç»¼åˆè¯„åˆ†
        f.write("ğŸ¯ ç»¼åˆè¯„åˆ†\n")
        f.write("-"*30 + "\n")
        f.write(f"æ–°é—»æƒ…ç»ªè¯„åˆ†ï¼š{scores['sentiment']:.1f}/100 (æƒé‡40%)\n")
        f.write(f"æŠ€æœ¯æŒ‡æ ‡è¯„åˆ†ï¼š{scores['technical']:.1f}/100 (æƒé‡60%)\n")
        f.write(f"ç»¼åˆè¯„åˆ†ï¼š{scores['final']:.1f}/100\n\n")
        
        # æ“ä½œå»ºè®®
        f.write("ğŸ’¡ æ“ä½œå»ºè®®\n")
        f.write("-"*30 + "\n")
        f.write(f"å»ºè®®ï¼š{suggestion}\n")
        f.write(f"ç½®ä¿¡åº¦ï¼š{confidence}\n")
        f.write(f"é£é™©ç­‰çº§ï¼š{'ä½' if scores['final'] >= 65 else ('ä¸­' if scores['final'] >= 45 else 'é«˜')}\n\n")
        
        # é£é™©æç¤º
        f.write("âš ï¸ é£é™©æç¤º\n")
        f.write("-"*30 + "\n")
        f.write("1. æœ¬åˆ†æä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®\n")
        f.write("2. è‚¡å¸‚æœ‰é£é™©ï¼ŒæŠ•èµ„éœ€è°¨æ…\n")
        f.write("3. è¯·ç»“åˆè‡ªèº«é£é™©æ‰¿å—èƒ½åŠ›åšå‡ºæŠ•èµ„å†³ç­–\n")
        f.write("4. å»ºè®®åˆ†æ•£æŠ•èµ„ï¼Œä¸è¦å°†æ‰€æœ‰èµ„é‡‘æŠ•å…¥å•ä¸€è‚¡ç¥¨\n")
    
    print(f"\nåˆ†æç»“æœå·²ä¿å­˜è‡³ {filename}")

# å¯é€‰æç¤ºï¼šå¦‚éœ€è®¾ç½®è‡ªåŠ¨æ¯å¤©è¿è¡Œï¼Œå¯ä½¿ç”¨ç³»ç»Ÿè®¡åˆ’ä»»åŠ¡/cron é…åˆæ­¤è„šæœ¬ã€‚
# Windows ç”¨æˆ·å¯ç”¨ä»»åŠ¡è®¡åˆ’ç¨‹åºè®¾ç½®æ¯å¤©9:00è¿è¡Œæ­¤è„šæœ¬
# macOS/Linux ç”¨æˆ·å¯æ·»åŠ  cron ä»»åŠ¡ï¼Œä¾‹å¦‚ï¼š
# 0 9 * * * /usr/bin/python3 /è·¯å¾„/wuxi_analysis.py >> /è·¯å¾„/log.txt 2>&1

def send_wechat(msg, title="wuxi_analysisåˆ†æç»“æœ"):
    SCKEY = os.getenv('SERVERCHAN_KEY', "SCT288761Tm49DLoHpETtgBZVHFLHmwvag")
    url = f"https://sctapi.ftqq.com/{SCKEY}.send"
    data = {"title": title, "desp": msg}
    try:
        resp = requests.post(url, data=data, timeout=10)
        print("å¾®ä¿¡æ¨é€ç»“æœ:", resp.text)
    except Exception as e:
        print("å¾®ä¿¡æ¨é€å¤±è´¥:", e)

if __name__ == "__main__":
    print("=== è¯æ˜åº·å¾·è‚¡ç¥¨åˆ†æç³»ç»Ÿ ===")
    if OFFLINE_MODE:
        print("ğŸ“± å½“å‰è¿è¡Œæ¨¡å¼ï¼šç¦»çº¿æ¨¡å¼ï¼ˆä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼‰")
    else:
        print("ğŸŒ å½“å‰è¿è¡Œæ¨¡å¼ï¼šåœ¨çº¿æ¨¡å¼ï¼ˆè·å–çœŸå®æ•°æ®ï¼‰")
    
    for stock in stock_list:
        print(f"\n========== æ­£åœ¨åˆ†æï¼š{stock['name']}ï¼ˆ{stock['code']}ï¼‰ ==========")
        
        # è·å–æ–°é—»æ•°æ®
        if OFFLINE_MODE:
            news_list = generate_mock_news_data()
            print(f"ğŸ“° ç”Ÿæˆ {len(news_list)} æ¡æ¨¡æ‹Ÿæ–°é—»")
        else:
            news_list = fetch_news(stock_code=stock['code'], max_pages=2)
        
        sentiment_label, pos_count, neu_count, neg_count, avg_score = analyze_sentiment(news_list)
        
        # è·å–è‚¡ç¥¨æ•°æ®
        if OFFLINE_MODE:
            df = generate_mock_stock_data(stock['code'], days=100)
            print("ğŸ“Š ä½¿ç”¨æ¨¡æ‹Ÿè‚¡ç¥¨æ•°æ®")
        else:
            df, tech_ind = fetch_stock_data(stock_code=stock['code'])
            if tech_ind is None:
                print("æ— æ³•è·å–è‚¡ç¥¨æ•°æ®ï¼Œè·³è¿‡ã€‚")
                continue
        
        # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
        if OFFLINE_MODE:
            df['MA5'] = df['Close'].rolling(window=5).mean()
            df['MA10'] = df['Close'].rolling(window=10).mean()
            df['MA20'] = df['Close'].rolling(window=20).mean()
            df['EMA12'] = df['Close'].ewm(span=12, adjust=False).mean()
            df['EMA26'] = df['Close'].ewm(span=26, adjust=False).mean()
            df['Diff'] = df['EMA12'] - df['EMA26']
            df['DEA'] = df['Diff'].ewm(span=9, adjust=False).mean()
            df['MACD_hist'] = 2 * (df['Diff'] - df['DEA'])
            
            # KDJè®¡ç®—
            low_list = df['Low'].rolling(window=9).min()
            high_list = df['High'].rolling(window=9).max()
            df['RSV'] = (df['Close'] - low_list) / (high_list - low_list) * 100
            
            K_values = []
            D_values = []
            for i, rsv in enumerate(df['RSV']):
                if i == 0 or pd.isna(rsv):
                    K = 50.0
                    D = 50.0
                else:
                    if pd.isna(rsv):
                        rsv = K_values[-1]
                    K = K_values[-1] * 2/3 + rsv * 1/3
                    D = D_values[-1] * 2/3 + K * 1/3
                K_values.append(K)
                D_values.append(D)
            
            df['K'] = K_values
            df['D'] = D_values
            df['J'] = 3 * df['K'] - 2 * df['D']
            
            # è·å–æœ€æ–°æ•°æ®
            latest = df.iloc[-1]
            recent_vol_avg = df['Volume'].iloc[-6:-1].mean() if len(df) > 5 else df['Volume'].mean()
            
            tech_ind = {
                'last_date': latest['Date'].strftime("%Y-%m-%d"),
                'last_close': latest['Close'],
                'pct_change': latest['PctChange'],
                'volume': latest['Volume'],
                'ma5': latest['MA5'],
                'ma10': latest['MA10'],
                'ma20': latest['MA20'],
                'diff': latest['Diff'],
                'dea': latest['DEA'],
                'macd_hist': latest['MACD_hist'],
                'K': latest['K'],
                'D': latest['D'],
                'J': latest['J'],
                'volume_high': latest['Volume'] > 1.2 * recent_vol_avg,
                'oversold': latest['K'] < 20 and latest['D'] < 20,
                'overbought': latest['K'] > 80 and latest['D'] > 80
            }

        print(f"\nğŸ“ˆ æœ€è¿‘äº¤æ˜“æ—¥({tech_ind['last_date']})æ”¶ç›˜: {tech_ind['last_close']:.2f} å…ƒ  æ¶¨è·Œ: {tech_ind['pct_change']:.2f}%  æˆäº¤é‡: {tech_ind['volume']:,}")
        print(f"ğŸ“Š å‡çº¿: MA5={tech_ind['ma5']:.2f}, MA10={tech_ind['ma10']:.2f}, MA20={tech_ind['ma20']:.2f}")
        if tech_ind['K'] < 20 or tech_ind['D'] < 20:
            kdj_status = "è¶…å–åŒº"
        elif tech_ind['K'] > 80 or tech_ind['D'] > 80:
            kdj_status = "è¶…ä¹°åŒº"
        else:
            kdj_status = "ä¸­æ€§åŒº"
        print(f"ğŸ“‰ KDJæŒ‡æ ‡: K={tech_ind['K']:.1f}, D={tech_ind['D']:.1f}, J={tech_ind['J']:.1f} ({kdj_status})")
        macd_status = "å¤šå¤´" if tech_ind['diff'] > tech_ind['dea'] else "ç©ºå¤´"
        print(f"ğŸ“Š MACDæŒ‡æ ‡: DIF={tech_ind['diff']:.2f}, DEA={tech_ind['dea']:.2f}, çŠ¶æ€: {macd_status}è¶‹åŠ¿")

        # ç»¼åˆè¯„ä¼°
        suggestion, confidence, final_score, sentiment_score, tech_score = evaluate_signals(sentiment_label, tech_ind, avg_score)
        
        print("\n========= ç»¼åˆåˆ†æç»“è®º =========")
        print(f"ğŸ“° æ–°é—»é¢æƒ…ç»ª: {sentiment_label}ï¼ŒğŸ“ˆ æŠ€æœ¯é¢ä¿¡å·: {'è¶…å–' if tech_ind['oversold'] else ('è¶…ä¹°' if tech_ind['overbought'] else 'æ­£å¸¸')}")
        print(f"ğŸ¯ ç»¼åˆè¯„åˆ†: {final_score:.1f}/100 (æ–°é—»{sentiment_score:.1f} + æŠ€æœ¯{tech_score:.1f})")
        print(f"ğŸ’¡ æ“ä½œå»ºè®®ï¼š{suggestion} (ç½®ä¿¡åº¦: {confidence})")

        # ä¿å­˜ç»“æœæ–‡æœ¬
        filename_txt = f"{stock['name']}_åˆ†æç»“æœ.txt"
        scores = {
            'sentiment': sentiment_score,
            'technical': tech_score,
            'final': final_score
        }
        save_result_to_file(sentiment_label, tech_ind, suggestion, confidence, scores, filename=filename_txt, stock_name=stock['name'])

        # ç”Ÿæˆå¯è§†åŒ–å›¾ï¼ˆä¿å­˜ä¸ºPNGï¼‰
        try:
            import matplotlib.pyplot as plt
            import matplotlib.font_manager as fm
            
            # è®¾ç½®ä¸­æ–‡å­—ä½“
            plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
            plt.rcParams['axes.unicode_minus'] = False
            
            plt.figure(figsize=(12, 6))
            df_tail = df.tail(30)
            plt.plot(df_tail['Date'], df_tail['Close'], label='æ”¶ç›˜ä»·', linewidth=2)
            plt.plot(df_tail['Date'], df_tail['MA5'], label='MA5', alpha=0.7)
            plt.plot(df_tail['Date'], df_tail['MA10'], label='MA10', alpha=0.7)
            plt.plot(df_tail['Date'], df_tail['MA20'], label='MA20', alpha=0.7)
            plt.xticks(rotation=45)
            plt.legend()
            plt.title(f"{stock['name']} æœ€è¿‘30æ—¥èµ°åŠ¿")
            plt.grid(True, alpha=0.3)
            plt.tight_layout()
            plt.savefig(f"{stock['name']}_èµ°åŠ¿å›¾.png", dpi=150, bbox_inches='tight')
            plt.close()
            print(f"ğŸ“Š èµ°åŠ¿å›¾å·²ä¿å­˜ä¸º {stock['name']}_èµ°åŠ¿å›¾.png")
        except Exception as e:
            print(f"âŒ ç»˜å›¾å¤±è´¥: {e}")

        # å…¬å‘Šå…³é”®è¯è¯†åˆ«ç¤ºä¾‹ï¼ˆç®€åŒ–ç‰ˆï¼‰
        risk_keywords = ['å‡æŒ', 'é—®è¯¢å‡½', 'è¯‰è®¼', 'äºæŸ', 'ä¸‹ä¿®', 'é€€å¸‚']
        warning_news = [title for _, title in news_list if any(k in title for k in risk_keywords)]
        if warning_news:
            print("âš ï¸ é£é™©å…¬å‘Šæç¤ºï¼š")
            for title in warning_news:
                print(" -", title)

        # ç•™å‡ºå¾®ä¿¡æˆ–é‚®ç®±æ¨é€æ¥å£ï¼ˆå¯æ¥å…¥ serveré…±ã€ä¼ä¸šå¾®ä¿¡æœºå™¨äººï¼‰
        # send_alert_via_wechat(f"{stock['name']} å»ºè®®ï¼š{suggestion}")
        
        print("\n" + "="*50)
        print("âœ… åˆ†æå®Œæˆï¼")

        # å‡è®¾åˆ†æç»“æœä¸º result_str
        try:
            result_str = ""
            # ...åŸæœ‰åˆ†æä»£ç ...
            # å¦‚æœæœ‰printè¾“å‡ºï¼Œæ•è·ä¸ºresult_str
            import io, sys
            buf = io.StringIO()
            sys_stdout = sys.stdout
            sys.stdout = buf
            # ====== åˆ†æä¸»é€»è¾‘å¼€å§‹ ======
            # è¯·å°†ä½ çš„ä¸»åˆ†æå‡½æ•°æ”¾åœ¨è¿™é‡Œï¼Œä¾‹å¦‚ï¼š
            # main()
            # ====== åˆ†æä¸»é€»è¾‘ç»“æŸ ======
            sys.stdout = sys_stdout
            result_str = buf.getvalue()
            print(result_str)
            send_wechat(result_str, "wuxi_analysisåˆ†æç»“æœ")
        except Exception as e:
            send_wechat(f"åˆ†æå¤±è´¥: {e}", "wuxi_analysisåˆ†æå¼‚å¸¸")